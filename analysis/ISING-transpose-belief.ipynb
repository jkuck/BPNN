{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ATTRACTIVE_FLAG=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import autograd\n",
    "import pickle\n",
    "import wandb\n",
    "import random\n",
    "\n",
    "from nn_models import lbp_message_passing_network, GIN_Network_withEdgeFeatures\n",
    "from ising_model.pytorch_dataset import build_factorgraph_from_SpinGlassModel\n",
    "from ising_model.spin_glass_model import SpinGlassModel\n",
    "from factor_graph import FactorGraphData\n",
    "from factor_graph import DataLoader_custom as DataLoader_pytorchGeometric\n",
    "\n",
    "from ising_model.pytorch_geometric_data import spinGlass_to_torchGeometric\n",
    "\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import parameters\n",
    "from parameters import ROOT_DIR, alpha, alpha2, SHARE_WEIGHTS, BETHE_MLP, NUM_MLPS\n",
    "import cProfile\n",
    "\n",
    "MODEL_MAP_FLAG = False\n",
    "CLASSIFICATION_FLAG = True\n",
    "TRAINING_FLAG = False\n",
    "BETHE_MLP = False\n",
    "ATTRACTIVE_FIELD = True\n",
    "LEARNING_RATE = 1e-6\n",
    "LR_DECAY_FLAG = False\n",
    "ALPHA = alpha\n",
    "ALPHA2 = alpha2\n",
    "MSG_PASSING_ITERS = 50\n",
    "SHARE_WEIGHTS = False\n",
    "\n",
    "\n",
    "MODE = \"train\" #run \"test\" or \"train\" mode\n",
    "\n",
    "TEST_TRAINED_MODEL = True \n",
    "EXPERIMENT_NAME = 'trained_MAP_attrField_10layer_2MLPs_noFinalBetheMLP/' #used for saving results when MODE='test'\n",
    "\n",
    "USE_WANDB = False\n",
    "####### Training PARAMETERS #######\n",
    "MAX_FACTOR_STATE_DIMENSIONS = 2\n",
    "EPSILON = 0 #set factor states with potential 0 to EPSILON for numerical stability\n",
    "SHARE_WEIGHTS = True if not TRAINING_FLAG  else SHARE_WEIGHTS\n",
    "MODEL_NAME = \"MAP_spinGlass_%dlayer_alpha=%f.pth\" % (MSG_PASSING_ITERS, parameters.alpha)\n",
    "TRAINED_MODELS_DIR = ROOT_DIR + \"trained_models_map/\" #trained models are stored here\n",
    "\n",
    "##########################################################################################################\n",
    "N_MIN_TRAIN = 3\n",
    "N_MAX_TRAIN = 3\n",
    "F_MAX_TRAIN = .1\n",
    "C_MAX_TRAIN = 5.0\n",
    "ATTRACTIVE_FIELD_TRAIN = ATTRACTIVE_FIELD\n",
    "\n",
    "N_MIN_VAL = 3\n",
    "N_MAX_VAL = 3\n",
    "F_MAX_VAL = .1\n",
    "C_MAX_VAL = 5.0\n",
    "ATTRACTIVE_FIELD_VAL = ATTRACTIVE_FIELD\n",
    "\n",
    "REGENERATE_DATA = False\n",
    "DATA_DIR = \"./data/spin_glass_map/\"\n",
    "\n",
    "TRAINING_DATA_SIZE = 50\n",
    "VAL_DATA_SIZE = 50#100\n",
    "TEST_DATA_SIZE = 200\n",
    "\n",
    "TRAIN_BATCH_SIZE=50\n",
    "VAL_BATCH_SIZE=50\n",
    "\n",
    "EPOCH_COUNT = 5000 if TRAINING_FLAG else 5\n",
    "PRINT_FREQUENCY = 10 if TRAINING_FLAG else 1\n",
    "VAL_FREQUENCY = 10 if TRAINING_FLAG else 1\n",
    "SAVE_FREQUENCY = 100 if TRAINING_FLAG else 1\n",
    "\n",
    "TEST_DATSET = 'val' \n",
    "\n",
    "##### Optimizer parameters #####\n",
    "STEP_SIZE=(EPOCH_COUNT//4)\n",
    "LR_DECAY=.5\n",
    "if ATTRACTIVE_FIELD_TRAIN == True:\n",
    "        LEARNING_RATE = LEARNING_RATE\n",
    "else:\n",
    "    LEARNING_RATE = LEARNING_RATE\n",
    "\n",
    "def get_dataset(dataset_type):\n",
    "    '''\n",
    "    Store/load a list of SpinGlassModels\n",
    "    When using, convert to BPNN or GNN form with either\n",
    "    build_factorgraph_from_SpinGlassModel(pytorch_geometric=True) for BPNN or spinGlass_to_torchGeometric() for GNN\n",
    "    '''\n",
    "    assert(dataset_type in ['train', 'val', 'test'])\n",
    "    if dataset_type == 'train':\n",
    "        datasize = TRAINING_DATA_SIZE\n",
    "        ATTRACTIVE_FIELD = ATTRACTIVE_FIELD_TRAIN\n",
    "        N_MIN = N_MIN_TRAIN\n",
    "        N_MAX = N_MAX_TRAIN\n",
    "        F_MAX = F_MAX_TRAIN\n",
    "        C_MAX = C_MAX_TRAIN\n",
    "    elif dataset_type == 'val':\n",
    "        datasize = VAL_DATA_SIZE\n",
    "        ATTRACTIVE_FIELD = ATTRACTIVE_FIELD_VAL\n",
    "        N_MIN = N_MIN_VAL\n",
    "        N_MAX = N_MAX_VAL\n",
    "        F_MAX = F_MAX_VAL\n",
    "        C_MAX = C_MAX_VAL\n",
    "    else:\n",
    "        datasize = TEST_DATA_SIZE\n",
    "        ATTRACTIVE_FIELD = ATTRACTIVE_FIELD_TEST\n",
    "\n",
    "    dataset_file = DATA_DIR + dataset_type + '%d_%d_%d_%.2f_%.2f_attField=%s.pkl' % (datasize, N_MIN, N_MAX, F_MAX, C_MAX, ATTRACTIVE_FIELD)\n",
    "    if REGENERATE_DATA or (not os.path.exists(dataset_file)):\n",
    "        print(\"REGENERATING DATA!!\")\n",
    "        spin_glass_models_list = [SpinGlassModel(N=random.randint(N_MIN, N_MAX),\\\n",
    "                                                f=np.random.uniform(low=0, high=F_MAX),\\\n",
    "                                                c=np.random.uniform(low=0, high=C_MAX),\\\n",
    "                                                attractive_field=ATTRACTIVE_FIELD) for i in range(datasize)]\n",
    "        if not os.path.exists(DATA_DIR):\n",
    "            os.makedirs(DATA_DIR)\n",
    "        with open(dataset_file, 'wb') as f:\n",
    "            pickle.dump(spin_glass_models_list, f)\n",
    "    else:\n",
    "        with open(dataset_file, 'rb') as f:\n",
    "            spin_glass_models_list = pickle.load(f)\n",
    "    return spin_glass_models_list\n",
    "\n",
    "\n",
    "spin_glass_models_list_train = get_dataset(dataset_type='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Factor Beliefs\n",
    "from ising_model.libdai_utils import *\n",
    "def bp_factor_marginals(sg_model, maxiter=None, updates=\"SEQRND\", damping=None, map_flag=False):\n",
    "    if maxiter is None:\n",
    "        maxiter=LIBDAI_LBP_ITERS\n",
    "    N = sg_model.lcl_fld_params.shape[0]\n",
    "\n",
    "    # Set some constants\n",
    "    maxiter = maxiter\n",
    "    tol = 1e-9\n",
    "    verb = 1\n",
    "    # Store the constants in a PropertySet object\n",
    "    opts = dai.PropertySet()\n",
    "    opts[\"maxiter\"] = str(maxiter)   # Maximum number of iterations\n",
    "    opts[\"tol\"] = str(tol)           # Tolerance for convergence\n",
    "    opts[\"verbose\"] = str(verb)      # Verbosity (amount of output generated)bpopts[\"updates\"] = \"SEQRND\"\n",
    "    opts[\"updates\"] = updates\n",
    "    opts[\"logdomain\"] = \"1\"\n",
    "    if damping is not None:\n",
    "        opts[\"damping\"] = str(damping)\n",
    "    opts['inference'] = ('MAXPROD' if map_flag else 'SUMPROD')\n",
    "\n",
    "    sg_FactorGraph = build_libdaiFactorGraph_from_SpinGlassModel(sg_model, fixed_variables={})\n",
    "    bp = dai.BP( sg_FactorGraph, opts )\n",
    "    bp.init()\n",
    "    bp.run()\n",
    "\n",
    "    return np.array([\n",
    "        [bp.beliefF(i)[j] for j in range(4)]\n",
    "        for i in range(N*N, sg_FactorGraph.nrFactors())\n",
    "    ])\n",
    "\n",
    "def exact_factor_marginals(sg_model, verbose=False, map_flag=True, classification_flag=True):\n",
    "    # Set some constants\n",
    "    maxiter = 10000\n",
    "    tol = 1e-9\n",
    "    verb = 0\n",
    "    # Store the constants in a PropertySet object\n",
    "    opts = dai.PropertySet()\n",
    "    opts[\"maxiter\"] = str(maxiter)   # Maximum number of iterations\n",
    "    opts[\"tol\"] = str(tol)           # Tolerance for convergence\n",
    "    opts[\"verbose\"] = str(verb)      # Verbosity (amount of output generated)bpopts[\"updates\"] = \"SEQRND\"\n",
    "    opts[\"updates\"] = \"HUGIN\"\n",
    "    opts[\"inference\"] = \"SUMPROD\"\n",
    "\n",
    "    N = sg_model.lcl_fld_params.shape[0]\n",
    "    log_marginals = np.zeros([N*(N-1)*2, 4])\n",
    "\n",
    "    sg_FactorGraph = build_libdaiFactorGraph_from_SpinGlassModel(sg_model, fixed_variables={})\n",
    "    jt = dai.JTree( sg_FactorGraph, opts )\n",
    "    jt.init()\n",
    "    jt.run()\n",
    "    logZ = jt.logZ()\n",
    "    for rol in range(N):\n",
    "        for col in range(N-1):\n",
    "            vi = rol*N+col\n",
    "            for si, states in enumerate([[-1,-1],[-1,1],[1,-1],[1,1]]):\n",
    "                s1, s2 = states\n",
    "                sg_FactorGraph = build_libdaiFactorGraph_from_SpinGlassModel(sg_model, fixed_variables={vi:s1, vi+N:s2})\n",
    "                jt = dai.JTree( sg_FactorGraph, opts )\n",
    "                jt.init()\n",
    "                jt.run()\n",
    "                log_marginals[vi,si] = jt.logZ()\n",
    "    for col in range(N):\n",
    "        for rol in range(N-1):\n",
    "            vi = rol*N+col\n",
    "            for si, states in enumerate([[-1,-1],[-1,1],[1,-1],[1,1]]):\n",
    "                s1, s2 = states\n",
    "                sg_FactorGraph = build_libdaiFactorGraph_from_SpinGlassModel(sg_model, fixed_variables={vi:s1, vi+1:s2})\n",
    "                jt = dai.JTree( sg_FactorGraph, opts )\n",
    "                jt.init()\n",
    "                jt.run()\n",
    "                log_marginals[vi+N*(N-1),si] = jt.logZ()\n",
    "    probability = np.exp(log_marginals-logZ)\n",
    "    return probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.25422042 0.25660698 0.2405871  0.24858549]\n",
      " [0.25242154 0.23753386 0.25228563 0.25775896]\n",
      " [0.00193236 0.00193236 0.00193236 0.00193236]\n",
      " [0.25966197 0.23514555 0.23200535 0.27318713]\n",
      " [0.25673077 0.24797641 0.24895803 0.24633479]\n",
      " [0.00193236 0.00193236 0.00193236 0.00193236]\n",
      " [0.26211883 0.24870858 0.22783657 0.26133602]\n",
      " [0.23900813 0.25094727 0.2482073  0.2618373 ]\n",
      " [0.24110007 0.24611536 0.25370746 0.25907712]\n",
      " [0.25512227 0.23968525 0.24958491 0.25560757]\n",
      " [0.26693995 0.23776723 0.23572481 0.25956802]\n",
      " [0.24716978 0.25549497 0.24449754 0.25283771]]\n",
      "[[0.25421518 0.24059234 0.25661223 0.24858025]\n",
      " [0.26211819 0.22783721 0.24870922 0.26133538]\n",
      " [0.25241895 0.25228824 0.23753645 0.25775636]\n",
      " [0.23898718 0.24822825 0.25096822 0.26181635]\n",
      " [0.26415741 0.23850734 0.22305801 0.27427723]\n",
      " [0.25966134 0.23200598 0.23514618 0.2731865 ]\n",
      " [0.25511893 0.24958826 0.23968859 0.25560422]\n",
      " [0.25670846 0.24898034 0.24799872 0.24631247]\n",
      " [0.26693779 0.23572696 0.23776939 0.25956585]\n",
      " [0.25668013 0.23916038 0.24598463 0.25817487]\n",
      " [0.25354343 0.25214538 0.23812389 0.2561873 ]\n",
      " [0.2604955  0.23534501 0.24519331 0.25896618]]\n"
     ]
    }
   ],
   "source": [
    "exact_beliefs = [exact_factor_marginals(sg) for sg in spin_glass_models_list_train]\n",
    "bp_beliefs = [bp_factor_marginals(sg, damping=ALPHA) for sg in spin_glass_models_list_train]\n",
    "print(exact_beliefs[0])\n",
    "print(bp_beliefs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
